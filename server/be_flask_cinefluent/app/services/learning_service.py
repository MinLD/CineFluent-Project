from google.genai import types
import json
import base64
from ..utils.ai_engine import cinefluent_ai
from deep_translator import GoogleTranslator


def translate_text(text: str, target_lang: str = 'vi') -> str:
    try:
        if not text:
            return ""
        # translator = GoogleTranslator(source='auto', target=target_lang)
        return GoogleTranslator(source='auto', target=target_lang).translate(text)
    except Exception as e:
        print(f"Translation error: {e}")
        return text


def evaluate_audio_shadowing_service(original_text: str, audio_base64: str):
    shadowing_schema = {
        "type": "OBJECT",
        "properties": {
            "transcript": {"type": "STRING"},
            "score": {"type": "INTEGER"},
            "wrong_words": { 
                "type": "ARRAY",
                "items": {"type": "STRING"},
                "description": "List of words from the TARGET TEXT that were mispronounced or omitted"
            },
            "feedback": {"type": "STRING", "description": "ƒê√≥ng vai gi√°o vi√™n b·∫£n x·ª© kh√≥ t√≠nh: Ch·ªâ ra v√†i l·ªói sai quan tr·ªçng nh·∫•t (√¢m cu·ªëi, tr·ªçng √¢m, n·ªëi √¢m,IPA) v√† h∆∞·ªõng d·∫´n c√°ch s·ª≠a c·ª• th·ªÉ b·∫±ng ti·∫øng Vi·ªát. Gi·ªçng vƒÉn t·ª± nhi√™n. D∆∞·ªõi 20 t·ª´."}
        },
        "required": ["transcript", "score", "wrong_words"]
    }


    optimized_prompt = f"Target text: {original_text}"

    try:

        response = cinefluent_ai.models.generate_content(
            model="gemini-2.5-flash",
            contents=[
                {
                    "parts": [
                        {"text": optimized_prompt},
                        {
                            "inline_data": {
                                "mime_type": "audio/webm",
                                "data": audio_base64
                            }
                        }
                    ]
                }
            ],
            config=types.GenerateContentConfig(
                temperature=0.3,
                response_mime_type="application/json",
                response_schema=shadowing_schema  # <--- CH√åA KH√ìA T·ªêI ∆ØU ·ªû ƒê√ÇY
            )
        )

        result = json.loads(response.text)


        return {"success": True, "data": result}

    except Exception as e:
        error_str = str(e)
        print(f"L·ªói AI Audio Analysis: {error_str}")
        
        if "429" in error_str or "RESOURCE_EXHAUSTED" in error_str:
             return {"success": False, "error": "H·ªá th·ªëng ƒëang qu√° t·∫£i (Rate Limit). Vui l√≤ng th·ª≠ l·∫°i sau 30 gi√¢y."}
        
        return {"success": False, "error": error_str}

def get_quick_dictionary_service(word: str, context_sentence: str):
    dictionary_schema = {
        "type": "OBJECT",
        "properties": {
            "word": {"type": "STRING"},
            "ipa": {"type": "STRING"},
            "pos": {"type": "STRING", "description": "Part of speech"},
            "definition_vi": {"type": "STRING"},
            "example_en": {"type": "STRING"},
            "example_vi": {"type": "STRING"}
        },
        "required": ["word", "ipa", "pos", "definition_vi", "example_en", "example_vi"]
    }

    prompt = f"""
    Word: "{word}"
    Sentence: "{context_sentence}"

    Rules:
    - Meaning must match the sentence
    - One meaning only
    - "word" must be base form
    - definition_vi: ONE short Vietnamese sentence (max 20 words)

    Return JSON with:
    word, ipa, pos, definition_vi, example_en, example_vi
    """

    try:
        response = cinefluent_ai.models.generate_content(
            model="gemini-2.5-flash",
            contents=[prompt],
            config=types.GenerateContentConfig(
                temperature=0.3,
                response_mime_type="application/json",
                response_schema=dictionary_schema
            )
        )

        result = json.loads(response.text)
        return {"success": True, "data": result}

    except Exception as e:
        error_str = str(e)
        print(f"L·ªói Quick Dictionary: {error_str}")
        if "429" in error_str or "RESOURCE_EXHAUSTED" in error_str:
            return {"success": False, "error": "H·ªá th·ªëng ƒëang qu√° t·∫£i. Vui l√≤ng th·ª≠ l·∫°i sau."}
        return {"success": False, "error": error_str}


def suggest_multiple_categories(title: str, year: str = None):
  
    category_list_schema = {
        "type": "OBJECT",
        "properties": {
            "categories": {
                "type": "ARRAY",
                "items": {"type": "STRING"}
            }
        },
        "required": ["categories"]
    }

    year_str = f" ({year})" if year else ""
    prompt = f"""
    Title: "{title}{year_str}"

    H√£y g·ª£i √Ω danh s√°ch c√°c th·ªÉ lo·∫°i phim (Genres/Themes) ph√π h·ª£p nh·∫•t b·∫±ng ti·∫øng Vi·ªát.
    
    Quy ƒë·ªãnh:
    - Tr·∫£ v·ªÅ danh s√°ch t·ª´ 2-5 th·ªÉ lo·∫°i quan tr·ªçng nh·∫•t.
    - T√™n th·ªÉ lo·∫°i ph·∫£i ph·ªï th√¥ng, ng·∫Øn g·ªçn (1-3 t·ª´).
    - V√≠ d·ª•: "H√†nh ƒë·ªông", "Vi·ªÖn t∆∞·ªüng", "L√£ng m·∫°n", "Ho·∫°t h√¨nh", "Gia ƒë√¨nh", "Kinh d·ªã".
    - Vi·∫øt hoa ch·ªØ c√°i ƒë·∫ßu cho m·ªói t·ª´.

    Ch·ªâ tr·∫£ v·ªÅ JSON.
    """

    try:
        response = cinefluent_ai.models.generate_content(
            model="gemini-2.5-flash",
            contents=[prompt],
            config=types.GenerateContentConfig(
                temperature=0.4,
                response_mime_type="application/json",
                response_schema=category_list_schema
            )
        )

        result = json.loads(response.text)
        categories = result.get("categories", [])
        print(f"‚úÖ AI Suggested Categories: {categories}")
        return {"success": True, "data": categories}

    except Exception as e:
        print(f"‚ùå L·ªói AI Multiple Category Suggestion: {str(e)}")
        if 'response' in locals() and hasattr(response, 'text'):
            print(f"üîç AI Raw Response: {response.text}")
        # Fallback c∆° b·∫£n
        return {"success": False, "error": str(e), "data": ["Phim"]}


def translate_batch(texts: list[str], target_lang: str = 'vi') -> list[str]:
    """
    D·ªãch danh s√°ch vƒÉn b·∫£n sang ng√¥n ng·ªØ ƒë√≠ch s·ª≠ d·ª•ng Batch request.
    T·ªëi ∆∞u h√≥a t·ªëc ƒë·ªô b·∫±ng c√°ch g·ªôp nhi·ªÅu c√¢u th√†nh 1 request.
    """
    if not texts:
        return []

    from deep_translator import GoogleTranslator
    import time

    def _translate_with_retry(text, max_retries=3):
        for attempt in range(max_retries):
            try:
                return GoogleTranslator(source='auto', target=target_lang).translate(text)
            except Exception as e:
                error_str = str(e)
                # Check for rate limit errors
                if '429' in error_str or 'Too Many Requests' in error_str:
                    if attempt < max_retries - 1:
                        time.sleep((2 ** attempt) * 1)
                    else:
                        raise e
                else:
                    raise e
        return text

    # T√≠nh batch size ƒë·ªông
    total_chars = sum(len(text) for text in texts)
    avg_chars = total_chars / len(texts) if texts else 50
    
    MAX_CHARS_PER_BATCH = 4500
    SEPARATOR = ' |||SUBTITLE_SEP||| '
    SEPARATOR_LENGTH = len(SEPARATOR)
    
    # T√≠nh batch size t·ªëi ∆∞u (tr√°nh qu√° d√†i)
    BATCH_SIZE = int(MAX_CHARS_PER_BATCH / (avg_chars + SEPARATOR_LENGTH))
    BATCH_SIZE = max(10, min(BATCH_SIZE, 100)) # Gi·ªõi h·∫°n 10-100 c√¢u/batch
    
    results = []
    
    for batch_idx in range(0, len(texts), BATCH_SIZE):
        batch = texts[batch_idx:batch_idx + BATCH_SIZE]
        
        try:
            combined_text = SEPARATOR.join(batch)
            translated_combined = _translate_with_retry(combined_text)
            
            # T√°ch l·∫°i
            parts = translated_combined.split('|||SUBTITLE_SEP|||')
            parts = [p.strip() for p in parts]
            
            # N·∫øu s·ªë l∆∞·ª£ng kh√¥ng kh·ªõp, fallback v·ªÅ d·ªãch t·ª´ng c√¢u
            if len(parts) != len(batch):
                print(f"Batch translation mismatch ({len(parts)} vs {len(batch)}). Fallback to single.")
                parts = []
                for text in batch:
                    try:
                        parts.append(_translate_with_retry(text))
                    except:
                         parts.append(text)
            
            results.extend(parts)
            
            # Delay nh·∫π
            if batch_idx + BATCH_SIZE < len(texts):
                time.sleep(0.5)
                
        except Exception as e:
            print(f"Batch translation error: {e}. Fallback to single.")
            for text in batch:
                    try:
                        results.append(_translate_with_retry(text))
                    except:
                        results.append(text) # Gi·ªØ nguy√™n n·∫øu l·ªói
    
    return results



